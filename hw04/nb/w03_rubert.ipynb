{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "085eba0b-02fb-4e4a-8e72-cd85eac86129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from itertools import islice\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, \n",
    "    f1_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    accuracy_score\n",
    ")\n",
    "\n",
    "\n",
    "PATH_TRAIN = \"../data/train.jsonl\"\n",
    "PATH_TEST = \"../data/dev.jsonl\"\n",
    "\n",
    "\n",
    "def log(msg:str, headers=None):\n",
    "    dttm = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    if (\n",
    "        (\"__main__\" in globals() or \"__main__\" in locals())\n",
    "        and hasattr(__main__, \"__file__\")\n",
    "    ):\n",
    "        script = os.path.basename(__main__.__file__)\n",
    "    else:\n",
    "        script = \"jupyter\"\n",
    "    if headers is None:\n",
    "        headers = []\n",
    "    header_line = f\"[{dttm}][{script}]\" + \"\".join(f\"[{h}]\" for h in headers)\n",
    "    print(f\"{header_line} {msg}\")\n",
    "\n",
    "\n",
    "def batched(iterable, n):\n",
    "    # batched('ABCDEFG', 3) → ABC DEF G\n",
    "    if n < 1:\n",
    "        raise ValueError('n must be at least one')\n",
    "    it = iter(iterable)\n",
    "    while batch := tuple(islice(it, n)):\n",
    "        yield batch\n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "    records = []\n",
    "    with open(path) as fp:\n",
    "        for line in fp:\n",
    "            record = json.loads(line.strip())\n",
    "            records.append(record)\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare(df, batch_size=128):\n",
    "    df[\"tp\"] = df.question + \". \" + df.passage\n",
    "    texts = df.tp.tolist()\n",
    "    batches = batched(texts, batch_size)\n",
    "    return batches\n",
    "    \n",
    "\n",
    "def make_embs(batches):\n",
    "    b_vecs = []\n",
    "    for idx, batch in enumerate(batches):\n",
    "        if idx%5==0:\n",
    "            log(f\"{idx} batches complete\", [\"make_embs\"])\n",
    "        tokens = tokenizer(\n",
    "            batch, \n",
    "            return_tensors=\"pt\", \n",
    "            padding=True, \n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            vecs = (\n",
    "                model(**tokens)\n",
    "                .last_hidden_state\n",
    "                .mean(1)\n",
    "                .detach()\n",
    "                .numpy()\n",
    "            )\n",
    "        b_vecs.append(vecs)\n",
    "    return np.vstack(b_vecs)\n",
    "    \n",
    "\n",
    "def get_train_embs():\n",
    "    return get_embs(\"train.npy\", PATH_TRAIN)\n",
    "\n",
    "\n",
    "def get_test_embs():\n",
    "    return get_embs(\"test.npy\", PATH_TEST)\n",
    "\n",
    "\n",
    "def get_embs(filename, path_in, cache_dir=\"./\"):\n",
    "    fpath = os.path.join(cache_dir, filename)\n",
    "    if os.path.exists(fpath):\n",
    "        with open(fpath, 'rb') as fp:\n",
    "            embs = np.load(fp)\n",
    "    else:\n",
    "        batches = prepare(read_data(path_in))  # 590\n",
    "        embs = make_embs(batches)\n",
    "        with open(fpath, 'wb') as fp:\n",
    "            np.save(fp, embs)\n",
    "    return embs\n",
    "\n",
    "\n",
    "def get_scores(y_true, y_score, thr=0.5):\n",
    "    y_pred = (thr<y_score).astype(int)\n",
    "    auc = roc_auc_score(y_score=y_score, y_true=y_true)\n",
    "    f1 = f1_score(y_true=y_true, y_pred=y_pred)\n",
    "    prec = precision_score(y_true=y_true, y_pred=y_pred)\n",
    "    rec = recall_score(y_true=y_true, y_pred=y_pred)\n",
    "    acc = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    return {\n",
    "        \"auroc\": auc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"accuracy\": acc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "421c367f-e59d-420f-80ea-89b5ce1b0fd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
    "model = AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased\").eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5bd8e5-7e75-4715-aaa8-a9b88dd7f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем ruBert-эмбеддинги или загружаем из кэша\n",
    "x_train = get_train_embs()\n",
    "x_test = get_test_embs()\n",
    "d_train = read_data(PATH_TRAIN)\n",
    "d_test = read_data(PATH_TEST)\n",
    "y_train = d_train.answer.astype(int)\n",
    "y_test = d_test.answer.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d06b69c-e9f7-4c93-8c79-856b1815c917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5874, number of negative: 3553\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 9427, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.623104 -> initscore=0.502744\n",
      "[LightGBM] [Info] Start training from score 0.502744\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(min_child_samples=8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(min_child_samples=8)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(min_child_samples=8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = dict(min_child_samples=8) # 0.7706774951912803\n",
    "\n",
    "est = lgb.LGBMClassifier(**params)\n",
    "est.fit(x_train, d_train.answer.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2afa5eaa-6e78-4d53-84cf-c7145bba6920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auroc': 0.9976606494140341,\n",
       " 'f1': 0.966922378949105,\n",
       " 'precision': 0.9379100656104977,\n",
       " 'recall': 0.9977868573374191,\n",
       " 'accuracy': 0.9574626074042644}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores(\n",
    "    y_true=d_train.answer.values,\n",
    "    y_score=est.predict_proba(x_train)[:,1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d314e6b1-2706-4482-9df6-e06abd387424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auroc': 0.669559980610946,\n",
       " 'f1': 0.7656582871751171,\n",
       " 'precision': 0.6753100338218715,\n",
       " 'recall': 0.8839153959665519,\n",
       " 'accuracy': 0.6636085626911316}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores(\n",
    "    y_true=d_test.answer.values,\n",
    "    y_score=est.predict_proba(x_test)[:,1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe524bf3-31bd-46bb-9325-f655d9aa1695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9838c63-2601-428e-af0e-8dc8fe455f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b445ffa8-1211-42d8-a112-4b08a11a020f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9427, 768)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67e88461-7d60-4f71-98fd-5e714b3cdc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3270, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e16789-6a5a-45a6-ae3a-64db8e657c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d499bdcf-9a9a-4f2d-87f0-84b0c8df3889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0d8d8f-d276-452c-a41f-fc631804ad07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b6480-7c7b-43ec-a30f-b921a4915f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a813a9-93fb-4a1a-a5da-01e61d368afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c54a03-36f6-41e8-b8dc-8768106411a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa7dfd1-dbf5-4b7a-aec1-abc5b31be4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_train = prepare(read_data(PATH_TRAIN))  # 590\n",
    "b_test = prepare(read_data(PATH_TEST))  # 205\n",
    "len([b for b in b_train]), len([b for b in b_test])\n",
    "# (74, 26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8b4081-675d-48c3-9232-aa84db2fbfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embs_train = make_embs(b_train)\n",
    "# with open('train.npy', 'wb') as fp:\n",
    "#     np.save(fp, embs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe52212-0973-4b9f-bf3c-e7390b63a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embs_test = make_embs(b_test)\n",
    "# with open('test.npy', 'wb') as fp:\n",
    "#     np.save(fp, embs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0b401-2784-43a0-a208-e43ecd1f16d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68543caa-ea50-4f11-b8f2-cca5dee4a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = get_train_embs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38c9115-9942-4f2a-9a7d-bd07670da459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c788388-09e8-4cd9-980b-98c737a4ca62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f71c7f-ba75-4710-a45d-aa79d5d605c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3897f836-db50-44ba-80fd-7160c0689976",
   "metadata": {},
   "outputs": [],
   "source": [
    "590*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90a5269-2763-4851-a3ca-c7eec3d23f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368358ea-f508-4f37-b76c-3360d2edecce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa2a594-1af8-43c5-8ab4-6d412f4fd161",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack(\n",
    "    [\n",
    "        np.array([[1,2],[3,4]]),\n",
    "        np.array([[1,2],[3,4]])\n",
    "    ]\n",
    ").sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7579b758-4803-4227-8063-ef7caeb97916",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f2a83-7cc3-429e-a7b8-32875ec36638",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.last_hidden_state.mean(1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a913b55b-34c7-4661-b422-2cd052d97149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5675aa45-36d6-4f11-b0b4-31bb0a783cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = tokenizer(batch, return_tensors=\"pt\", padding=True)\n",
    "res = model(**tokens_train)\n",
    "\n",
    "# res.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a58007-d344-465a-b0b3-3acbd99e1e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece43ef1-ac55-47c1-8eaa-cf6453d2c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b4585-17eb-4a1d-92ae-2fe9d555a345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b4775-8cfc-469d-834e-972e54171eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba885ae-e0d6-4f92-827c-a2c688f152b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465306c3-f8b5-4eaf-8462-f4a1e98400da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f855f240-6521-44f4-82fa-130692f6ad0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f34065-ce61-4df6-bac2-15fa70f04da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = read_data(PATH_TRAIN)\n",
    "d_test = read_data(PATH_TEST)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "d_train[\"tp\"] = d_train.question + \". \" + d_train.passage\n",
    "d_test[\"tp\"] = d_test.question + \". \" + d_test.passage\n",
    "# tokens_train = d_train.tp.apply(lambda line: [x for x in gensim.utils.tokenize(line)]).tolist()\n",
    "# tokens_test = d_test.tp.apply(lambda line: [x for x in gensim.utils.tokenize(line)]).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f9141-59fe-451c-8c5e-d22f40ed3259",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train = d_train.tp.tolist()\n",
    "texts_test = d_test.tp.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6880a26-0069-41cb-94d2-37580a32e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_train = batched(texts_train, 16)\n",
    "b_test = batched(texts_test, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c13c2-5314-46c9-878e-1e935516fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in b_train:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726997c-2d87-4382-8f4c-89cea556ec33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokens_train = tokenizer(batch, return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224c9b87-1a54-4e2a-8d88-bccb8589b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51976589-0aba-4a79-9748-ba81a9b48c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_test = tokenizer(d_test.tp.tolist(), return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b30037-238a-4a65-a7a9-658ba0259ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce222c-c010-4887-9e20-dfe54f059a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(**tokens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eefe9d2-f3d6-435d-a4ed-ffd5785721a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
