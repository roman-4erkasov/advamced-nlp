{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30380e5-f13c-4d8e-8093-e8b28f55ef0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatuus/advanced-nlp/prj04_emb/vegpu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../src\")\n",
    "\n",
    "import re\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from utils import log\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def get_date(url):\n",
    "    dates = re.findall(r\"\\d\\d\\d\\d\\/\\d\\d\\/\\d\\d\", url)\n",
    "    return next(iter(dates), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce9f86ae-f119-47c8-9786-4c6f4ac42558",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/prepared.pkl\", \"rb\") as fp:\n",
    "    prepared = pkl.load(fp)\n",
    "vocabulary = prepared[\"vocabulary\"]\n",
    "texts = prepared[\"texts\"]\n",
    "contexts = prepared[\"contexts\"]\n",
    "test_texts = prepared[\"test_texts\"]\n",
    "y_train = prepared[\"y_train\"]\n",
    "y_test = prepared[\"y_test\"]\n",
    "text_train = prepared[\"texts_train\"]\n",
    "text_test = prepared[\"texts_test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea50239-7008-41c5-aa88-b2c243bf413e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b4dc7d1-f77d-4262-a3d6-5e9924c199ba",
   "metadata": {},
   "source": [
    "# XLM-RoBerta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ca08a7-697b-4b93-b954-dfaead4b7b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-base\").eval().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94cafc1a-3fa5-4f04-989a-144dc4845025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def batched(iterable, n):\n",
    "    # batched('ABCDEFG', 3) → ABC DEF G\n",
    "    if n < 1:\n",
    "        raise ValueError('n must be at least one')\n",
    "    it = iter(iterable)\n",
    "    while batch := tuple(islice(it, n)):\n",
    "        yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9b25263-de2a-496d-88a9-4d3d2a8f3baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [\n",
    "    \"Метод биологической очистки основан на способности некоторых видов микроорганизмов в определённых условиях использовать загрязняющие вещества в качестве своего питания. Множество микроорганизмов, составляющих активный ил биологического очистного сооружения, находясь в сточной жидкости, поглощает загрязняющие вещества внутрь клетки, где они под воздействием ферментов подвергаются биохимическим превращениям. При этом органические и некоторые виды неорганических загрязняющих веществ используются бактериальной клеткой в двух направлениях:\"*10,\n",
    "    \"Активный ил — биоценоз зоогенных скоплений (колоний) бактерий и простейших организмов, которые участвуют в очистке сточных вод. Применяется в биологической очистке сточных вод. Данный метод был изобретён в Великобритании в 1913 году. Биологическая очистка сточных вод осуществляется с целью удаления из них органических веществ, в том числе соединений азота и фосфора.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "344e8416-b779-434a-b797-e173c5683ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokens = tokenizer(\n",
    "    list(batch),\n",
    "    return_tensors='pt', \n",
    "    max_length=512, \n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    pad_to_max_length=True\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce51dfaf-5850-41c5-bc79-01c0ad9885c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46c5e0c2-71c5-4a67-b355-2c8cf5976c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "batches = batched(text_train, 16)\n",
    "for i, batch in enumerate(batches):\n",
    "    n += len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b0b6114-b6cb-49ad-8c71-e9646eae6a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63356"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857031da-4368-4327-859a-c74f89c26f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = batched(text_train, 16)\n",
    "n_batches = len([_ for b in batches])\n",
    "outputs = []\n",
    "batches = batched(text_train, 16)\n",
    "log(f\"starting loop over {n_batches=}\")\n",
    "for i, batch in enumerate(batches):\n",
    "    tokens = tokenizer(\n",
    "        batch,\n",
    "        return_tensors='pt', \n",
    "        max_length=512, \n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        pad_to_max_length=True\n",
    "    )    \n",
    "    input_ids=tokens[\"input_ids\"].cuda()\n",
    "    attention_mask=tokens[\"attention_mask\"].cuda()\n",
    "    log(\"\")\n",
    "    out = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "    out_batch = out.hidden_states[-1].squeeze().mean(0).detach().cpu().numpy()\n",
    "    outputs.append(out_batch)\n",
    "    del batch, tokens,input_ids, attention_mask, out, out_batch\n",
    "    log(f\"{i=}\")\n",
    "output = np.vstack(outputs)\n",
    "path = \"../data/xmlr_embs\"\n",
    "log(f\"saving data to \\\"{path}\\\"\")\n",
    "np.save(, output)\n",
    "log(\"END\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96a3b1f-f8f4-4e66-a116-f5f3f6408e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = batched(text_test, 16)\n",
    "n_batches = len([_ for b in batches])\n",
    "outputs = []\n",
    "batches = batched(text_test, 16)\n",
    "log(f\"starting loop over {n_batches=}\")\n",
    "for i, batch in enumerate(batches):\n",
    "    tokens = tokenizer(\n",
    "        list(batch),\n",
    "        return_tensors='pt', \n",
    "        max_length=512, \n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        pad_to_max_length=True\n",
    "    )    \n",
    "    input_ids=tokens[\"input_ids\"].cuda()\n",
    "    attention_mask=tokens[\"attention_mask\"].cuda()\n",
    "    out = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "    out_batch = out.hidden_states[-1].squeeze().mean(0).detach().cpu().numpy()\n",
    "    outputs.append(out_batch)\n",
    "    del batch, tokens,input_ids, attention_mask, out, out_batch\n",
    "    log(f\"{i=}\")\n",
    "output = np.vstack(outputs)\n",
    "path = \"../data/xmlr_embs_test\"\n",
    "log(f\"saving data to \\\"{path}\\\"\")\n",
    "np.save(path, output)\n",
    "log(\"END\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d47e17-5b49-476b-a5b1-2627f5dfce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735df934-bc32-4276-9575-f22827192a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b0a20a-05e3-4754-993f-aae0babec054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd64501-66fb-47c9-a361-72c1cc5255d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del batch, tokens, input_ids, attention_mask, out, out_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5800eb-0022-4f5f-9d13-ffe300addb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f566ae-c042-4b51-acbf-a6eefe35701b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "txt = text_train[31339]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dd3a73-f15c-49de-b98d-b7471d7c8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = tokenizer(txt, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e356cded-8d08-42d1-96f8-2c453e03a5ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_ids=tokens[\"input_ids\"].cuda()\n",
    "attention_mask=tokens[\"input_ids\"].cuda()\n",
    "o = model(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886e9acb-30c2-437b-9de8-218d61d852a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f38aa-e51e-4ad9-9a0b-ba574af8ba37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb557f9b-15c5-46fe-9f2b-4e01f7b0bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros((len(text_test), 768))\n",
    "for i, text in enumerate(text_test):\n",
    "    tokens = tokenizer(batch,return_tensors='pt', max_length=512)\n",
    "    out = model(**tokens, output_hidden_states=True)\n",
    "    X_test[i, :] = out.hidden_states[-1].mean(1).detach().numpy()\n",
    "    if i % 100 == 0:\n",
    "        log(f\"{i=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46138493-6a41-4531-bf9c-c45974bc1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5085a104-bbbf-452d-bb9e-d6881af636b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'est' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m p_train \u001b[38;5;241m=\u001b[39m \u001b[43mest\u001b[49m\u001b[38;5;241m.\u001b[39mpredict_proba(X_train)\n\u001b[1;32m      2\u001b[0m roc_auc_score(y_true\u001b[38;5;241m=\u001b[39my_train, y_score\u001b[38;5;241m=\u001b[39mp_train, multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'est' is not defined"
     ]
    }
   ],
   "source": [
    "p_train = est.predict_proba(X_train)\n",
    "roc_auc_score(y_true=y_train, y_score=p_train, multi_class=\"ovo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b614e3-bc9b-4f41-adef-f1fc0704da66",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test = est.predict_proba(X_test)\n",
    "roc_auc_score(y_true=y_test, y_score=p_test, multi_class=\"ovo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
