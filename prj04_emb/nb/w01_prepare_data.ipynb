{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f22eb275-4b70-4e5b-ac2b-53116b2a53c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle as pkl\n",
    "import datetime as dt\n",
    "from razdel import tokenize, sentenize\n",
    "from string import punctuation\n",
    "from vocabulary import Vocabulary\n",
    "\n",
    "\n",
    "def get_date(url):\n",
    "    dates = re.findall(r\"\\d\\d\\d\\d\\/\\d\\d\\/\\d\\d\", url)\n",
    "    return next(iter(dates), None)\n",
    "\n",
    "\n",
    "def get_texts(dataset):\n",
    "    texts = []\n",
    "    for text in dataset[\"text\"]:\n",
    "        for sentence in sentenize(text):\n",
    "            texts.append([token.text.lower() for token in tokenize(sentence.text) if token.text not in punctuation])\n",
    "\n",
    "    for title in dataset[\"title\"]:\n",
    "        texts.append([token.text.lower() for token in tokenize(title) if token.text not in punctuation])\n",
    "    return texts\n",
    "\n",
    "\n",
    "def build_contexts(tokenized_texts, vocabulary, window_size):\n",
    "    contexts = []\n",
    "    for tokens in tokenized_texts:\n",
    "        for i in range(len(tokens)):\n",
    "            central_word = vocabulary.get_index(tokens[i])\n",
    "            context = [\n",
    "                vocabulary.get_index(tokens[i + delta])\n",
    "                for delta in range(-window_size, window_size + 1)\n",
    "                if delta != 0 and i + delta >= 0 and i + delta < len(tokens)\n",
    "            ]\n",
    "            if len(context) != 2 * window_size:\n",
    "                continue\n",
    "            contexts.append((central_word, context))\n",
    "    return contexts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16360bfc-4c31-4e69-b58a-48e606a01b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['возобновление', 'нормального', 'сотрудничества', 'между', 'россией', 'и', 'нато', 'невозможно', 'пока', 'москва', 'не', 'будет', 'соблюдать', 'нормы', 'международного', 'права']\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"../lenta-ru-news.csv\", sep=',', quotechar='\\\"', escapechar='\\\\', encoding='utf-8', header=0)\n",
    "dataset[\"date\"] = dataset[\"url\"].apply(lambda x: dt.datetime.strptime(get_date(x), \"%Y/%m/%d\"))\n",
    "dataset = dataset[dataset[\"date\"] > \"2017-01-01\"]\n",
    "dataset[\"text\"] = dataset[\"text\"].apply(lambda x: x.replace(\"\\xa0\", \" \"))\n",
    "dataset[\"title\"] = dataset[\"title\"].apply(lambda x: x.replace(\"\\xa0\", \" \"))\n",
    "train_dataset = dataset[dataset[\"date\"] < \"2018-04-01\"]\n",
    "test_dataset = dataset[dataset[\"date\"] > \"2018-04-01\"]\n",
    "\n",
    "texts = get_texts(train_dataset)\n",
    "test_texts = get_texts(test_dataset)\n",
    "\n",
    "assert len(texts) == 827217\n",
    "assert len(texts[0]) > 0\n",
    "assert texts[0][0].islower()\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8249f752-7180-46c8-a18a-d4062c67a12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71186\n",
      "['в', 'и', 'на', '«', '»', 'что', 'с', 'по', '—', 'не', 'из', 'этом', 'об', 'о', 'он', 'за', 'года', 'россии', 'к', 'его', 'для', 'как', 'также', 'от', 'а', 'это', 'сообщает', 'до', 'году', 'после', 'сша', 'у', 'во', 'время', 'был', 'при', 'заявил', 'со', 'словам', 'рублей', 'будет', 'ее', 'она', 'но', 'ранее', 'их', 'они', 'было', 'тысяч', 'более', 'того', 'том', 'мы', 'были', 'я', 'которые', 'все', 'который', 'человек', 'под', '2016', 'из-за', 'лет', '2017', 'украины', 'марта', 'процентов', 'чтобы', 'долларов', 'глава', 'президент', 'этого', 'отметил', 'же', 'сказал', 'так', 'января', 'или', 'страны', 'ру', 'то', 'еще', 'области', 'данным', 'была', 'президента', 'около', 'сообщил', 'февраля', 'однако', 'компании', 'может', 'уже', 'один', 'рассказал', 'только', 'процента', '1', '10', 'июня']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = Vocabulary()\n",
    "vocabulary.build(texts)\n",
    "assert vocabulary.word2index[vocabulary.index2word[10]] == 10\n",
    "print(vocabulary.size)\n",
    "print(vocabulary.top(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a788454-1867-4577-9b9a-929ebd500945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1568, [17232, 26343, 135, 371]), (135, [26343, 1568, 371, 2]), (371, [1568, 135, 2, 695]), (2, [135, 371, 695, 2140]), (695, [371, 2, 2140, 216])]\n",
      "сотрудничества ['возобновление', 'нормального', 'между', 'россией']\n"
     ]
    }
   ],
   "source": [
    "contexts = build_contexts(texts, vocabulary, window_size=2)\n",
    "print(contexts[:5])\n",
    "print(vocabulary.get_word(contexts[0][0]), [vocabulary.get_word(index) for index in contexts[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c91c4f53-8d3c-4a84-a3b1-8347f3f80a91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/prepared.pkl\", \"wb\") as fp:\n",
    "    pkl.dump(\n",
    "        file=fp, \n",
    "        obj={\n",
    "            \"vocabulary\": vocabulary,\n",
    "            \"texts\": texts,\n",
    "            \"contexts\": contexts,\n",
    "            \"test_texts\": test_texts,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e08affb9-3d84-42d5-96c6-2ce2c5202587",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/prepared.pkl\", \"rb\") as fp:\n",
    "    prepared = pkl.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2bbd19-dd5f-4545-b8b7-da65e0ae45cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
